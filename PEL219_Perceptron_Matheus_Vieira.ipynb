{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "asjPSg-xNoZS",
        "7CiPx772BwTo"
      ],
      "authorship_tag": "ABX9TyNgRhaekvYtxDdk3aAcRfzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zewtta/PEL219_2025_RedesNeuraisArtificiais/blob/main/PEL219_Perceptron_Matheus_Vieira.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tarefa 1 - Perceptron**\n",
        "##Aluno: Matheus Vieira"
      ],
      "metadata": {
        "id": "37jDJ4ySr_7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Atividade 1 - Treinamento com o modelo .csv reduzido"
      ],
      "metadata": {
        "id": "asjPSg-xNoZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Teste perceptron com base no código de referência"
      ],
      "metadata": {
        "id": "kBArVbogk4x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, w=None):\n",
        "        \"\"\"\n",
        "        w: vetor de pesos incluindo bias (w0, w1, w2, ...)\n",
        "        Se None, será definido na primeira predição de acordo com #features.\n",
        "        \"\"\"\n",
        "        self.w = None if w is None else np.asarray(w, dtype=float)\n",
        "\n",
        "    @staticmethod\n",
        "    def _add_bias(X: np.ndarray) -> np.ndarray:\n",
        "        return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def _heaviside(z: np.ndarray) -> np.ndarray:\n",
        "        return (z >= 0).astype(int)\n",
        "\n",
        "    def net(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Calcula a soma ponderada (net) para um conjunto de amostras X (sem bias).\n",
        "        \"\"\"\n",
        "        Xb = self._add_bias(X)\n",
        "        # se os pesos não existem ainda, inicializa com zeros compatíveis\n",
        "        if self.w is None:\n",
        "            self.w = np.zeros(Xb.shape[1], dtype=float)\n",
        "        return Xb @ self.w\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Retorna a saída binária (0/1) aplicando a função degrau sobre net.\n",
        "        \"\"\"\n",
        "        return self._heaviside(self.net(X))\n",
        "\n",
        "# Lê CSV do GitHub\n",
        "url = \"https://raw.githubusercontent.com/Zewtta/PEL219_2025_RedesNeuraisArtificiais/e5a63434c13a8ac9a80d4d303b97a8c8de5b01d0/simple_diabetes.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# X: todas menos a última | y: última\n",
        "X = df.iloc[:, :-1].to_numpy(float)\n",
        "y = df.iloc[:, -1].to_numpy(int)\n",
        "\n",
        "# Instancia com os MESMOS pesos “chutados” do teu código (bias=-130, w1=1, w2=0)\n",
        "clf = Perceptron(w=[-130, 1, 0])\n",
        "\n",
        "# net e out\n",
        "net = clf.net(X)\n",
        "print(\"net:\\n\", net)\n",
        "\n",
        "out = clf.predict(X)\n",
        "print(\"out:\\n\", out)\n",
        "\n",
        "# acurácia\n",
        "acc = (out == y).mean()\n",
        "print(f\"Acurácia com w atual: {acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prgZQVM6N2Sn",
        "outputId": "691e8ea1-3def-4425-94b8-60a9a673a2e1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net:\n",
            " [-45. -41. -14. -33. -42. -38.  -8. -27. -24. -59. -27. -29. -42. -57.\n",
            " -86. -31. -35. -18. -17. -47. -29. -23. -50. -59. -37.  -5. -49.  -4.\n",
            " -34. -33. -31. -34. -37.  -2. -40. -16. -31. -21. -42. -30. -10. -19.\n",
            " -43. -55. -43. -57. -19. -45. -25. -22.  18.   7.  67.  38.  59.  66.\n",
            "  13.  17.  28.  41.  50.  46.  57.   3.   1.   7.   6.  33.  41.  25.\n",
            "  30.  16.  32.  40.  26.  58.  22.  33.   1.   4.  49.  64.  51.   9.\n",
            "  29.   5.  28.  18.  66.  32.  54.  10.  21.  47.  28.  32.  12.   4.\n",
            "  41.  51.]\n",
            "out:\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Acurácia com w atual: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2oFjtoAll8OL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceptron com Hebbian Learning"
      ],
      "metadata": {
        "id": "QwPCm9Wdl94p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, taxa=0.1, epocas=1000):\n",
        "        self.taxa = taxa\n",
        "        self.epocas = epocas\n",
        "        self.w = None\n",
        "        self.historico_acc = []\n",
        "\n",
        "    @staticmethod\n",
        "    def _add_bias(X):\n",
        "        return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def _heaviside(z):\n",
        "        return (z >= 0).astype(int)\n",
        "\n",
        "    def fit(self, X, y, plot=False):\n",
        "        Xb = self._add_bias(X)\n",
        "        self.w = np.zeros(Xb.shape[1])\n",
        "        melhor_acc, melhor_w = 0, self.w.copy()\n",
        "\n",
        "        for _ in range(self.epocas):\n",
        "            erros = 0\n",
        "            idx = np.arange(len(Xb))\n",
        "            np.random.shuffle(idx)\n",
        "            for i in idx:\n",
        "                net = np.dot(Xb[i], self.w)\n",
        "                out = np.heaviside(net, 0)\n",
        "                erro = y[i] - out\n",
        "                if erro != 0:\n",
        "                    self.w += self.taxa * erro * Xb[i]\n",
        "                    acc = (self.predict(X) == y).mean()\n",
        "                    self.historico_acc.append(acc)\n",
        "                    if acc > melhor_acc:\n",
        "                        melhor_acc, melhor_w = acc, self.w.copy()\n",
        "                    erros += 1\n",
        "            if erros == 0:\n",
        "                print(\"Convergiu!\")\n",
        "                break\n",
        "\n",
        "        self.w = melhor_w\n",
        "        print(f\"\\nMelhor acurácia: {melhor_acc:.3f}\")\n",
        "        print(f\"Pesos finais: {self.w}\")\n",
        "        if plot and self.historico_acc:\n",
        "            plt.plot(self.historico_acc)\n",
        "            plt.xlabel(\"Atualizações\")\n",
        "            plt.ylabel(\"Acurácia\")\n",
        "            plt.title(\"Evolução da Acurácia\")\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        Xb = self._add_bias(X)\n",
        "        return self._heaviside(np.dot(Xb, self.w))\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return (self.predict(X) == y).mean()\n",
        "\n",
        "\n",
        "# --- Execução direta ---\n",
        "url = \"https://raw.githubusercontent.com/Zewtta/PEL219_2025_RedesNeuraisArtificiais/e5a63434c13a8ac9a80d4d303b97a8c8de5b01d0/simple_diabetes.csv\"\n",
        "df = pd.read_csv(url)\n",
        "X = df.iloc[:, :-1].to_numpy(float)\n",
        "y = df.iloc[:, -1].to_numpy(int)\n",
        "\n",
        "# Normaliza (opcional, melhora convergência)\n",
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "modelo = Perceptron(taxa=0.3, epocas=3000).fit(X, y, plot=False)\n",
        "acc = modelo.score(X, y)\n",
        "print(f\"\\nAcurácia final: {acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-O4HlBpmE4Z",
        "outputId": "95bca4fb-54d5-4c44-f072-71bbdcf2ee0c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergiu!\n",
            "\n",
            "Melhor acurácia: 1.000\n",
            "Pesos finais: [0.         0.43290902 0.3389458 ]\n",
            "\n",
            "Acurácia final: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceptron Hebbian Learning com 80/20"
      ],
      "metadata": {
        "id": "8uIZ4jQ1BK-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, taxa=0.1, epocas=1000):\n",
        "        self.taxa = taxa\n",
        "        self.epocas = epocas\n",
        "        self.w = None\n",
        "        self.historico_acc = []\n",
        "\n",
        "    @staticmethod\n",
        "    def _add_bias(X):\n",
        "        return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def _heaviside(z):\n",
        "        return (z >= 0).astype(int)\n",
        "\n",
        "    def fit(self, X, y, plot=False):\n",
        "        Xb = self._add_bias(X)\n",
        "        self.w = np.zeros(Xb.shape[1])\n",
        "        melhor_acc, melhor_w = 0, self.w.copy()\n",
        "\n",
        "        for _ in range(self.epocas):\n",
        "            erros = 0\n",
        "            idx = np.arange(len(Xb))\n",
        "            np.random.shuffle(idx)\n",
        "            for i in idx:\n",
        "                net = np.dot(Xb[i], self.w)\n",
        "                out = np.heaviside(net, 0)\n",
        "                erro = y[i] - out\n",
        "                if erro != 0:\n",
        "                    self.w += self.taxa * erro * Xb[i]\n",
        "                    acc = (self.predict(X) == y).mean()\n",
        "                    self.historico_acc.append(acc)\n",
        "                    if acc > melhor_acc:\n",
        "                        melhor_acc, melhor_w = acc, self.w.copy()\n",
        "                    erros += 1\n",
        "            if erros == 0:\n",
        "                print(\"Convergiu!\")\n",
        "                break\n",
        "\n",
        "        self.w = melhor_w\n",
        "        print(f\"\\nMelhor acurácia (treino): {melhor_acc:.3f}\")\n",
        "        print(f\"Pesos finais: {self.w}\")\n",
        "        if plot and self.historico_acc:\n",
        "            plt.plot(self.historico_acc)\n",
        "            plt.xlabel(\"Atualizações\")\n",
        "            plt.ylabel(\"Acurácia\")\n",
        "            plt.title(\"Evolução da Acurácia (treino)\")\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        Xb = self._add_bias(X)\n",
        "        return self._heaviside(np.dot(Xb, self.w))\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return (self.predict(X) == y).mean()\n",
        "\n",
        "\n",
        "# --- Leitura dos dados\n",
        "url = \"https://raw.githubusercontent.com/Zewtta/PEL219_2025_RedesNeuraisArtificiais/e5a63434c13a8ac9a80d4d303b97a8c8de5b01d0/simple_diabetes.csv\"\n",
        "df = pd.read_csv(url)\n",
        "X = df.iloc[:, :-1].to_numpy(float)\n",
        "y = df.iloc[:, -1].to_numpy(int)\n",
        "\n",
        "# Normalização (melhor convergência)\n",
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "# --- Divisão treino/teste 80/20\n",
        "rng = np.random.default_rng(42)\n",
        "idx = rng.permutation(len(X))\n",
        "cut = int(0.8 * len(X))\n",
        "X_tr, X_te = X[idx[:cut]], X[idx[cut:]]\n",
        "y_tr, y_te = y[idx[:cut]], y[idx[cut:]]\n",
        "\n",
        "# --- Treinamento\n",
        "modelo = Perceptron(taxa=0.1, epocas=50).fit(X_tr, y_tr, plot=False)\n",
        "\n",
        "# --- Avaliação\n",
        "acc_tr = modelo.score(X_tr, y_tr)\n",
        "acc_te = modelo.score(X_te, y_te)\n",
        "\n",
        "print(f\"\\nAcurácia treino: {acc_tr:.3f}\")\n",
        "print(f\"Acurácia teste : {acc_te:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "his5qRkiBg0U",
        "outputId": "1ea9b20f-3fed-4855-f17e-5f2a28281f9c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergiu!\n",
            "\n",
            "Melhor acurácia (treino): 1.000\n",
            "Pesos finais: [0.         0.18242078 0.10168374]\n",
            "\n",
            "Acurácia treino: 1.000\n",
            "Acurácia teste : 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verificação do modelo"
      ],
      "metadata": {
        "id": "YBSLg_hjMNLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Carregar base Pima Indians ---\n",
        "url = \"https://raw.githubusercontent.com/Zewtta/PEL219_2025_RedesNeuraisArtificiais/e5a63434c13a8ac9a80d4d303b97a8c8de5b01d0/simple_diabetes.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "X = df.iloc[:, :-1].to_numpy(float)\n",
        "y = df.iloc[:, -1].to_numpy(int)\n",
        "\n",
        "# Separar treino/teste (80/20) ---\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Normalização (só com base no treino) ---\n",
        "scaler = StandardScaler()\n",
        "Xtr_n = scaler.fit_transform(X_tr)\n",
        "Xte_n = scaler.transform(X_te)\n",
        "\n",
        "# Treinar Perceptron (sklearn) ---\n",
        "modelo = Perceptron(\n",
        "    penalty=None,     # sem regularização (como o perceptron “clássico”)\n",
        "    alpha=0.0001,     # ignorado se penalty=None\n",
        "    max_iter=100,\n",
        "    eta0=0.1,         # taxa de aprendizado\n",
        "    tol=None,         # desliga early stopping\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo.fit(Xtr_n, y_tr)\n",
        "\n",
        "# Avaliar ---\n",
        "ytr_pred = modelo.predict(Xtr_n)\n",
        "yte_pred = modelo.predict(Xte_n)\n",
        "\n",
        "acc_tr = accuracy_score(y_tr, ytr_pred)\n",
        "acc_te = accuracy_score(y_te, yte_pred)\n",
        "\n",
        "print(f\"Acurácia treino: {acc_tr:.3f}\")\n",
        "print(f\"Acurácia teste : {acc_te:.3f}\")\n",
        "\n",
        "print(\"\\nRelatório (teste):\")\n",
        "print(classification_report(y_te, yte_pred, digits=3))\n",
        "\n",
        "print(\"Matriz de confusão (teste):\")\n",
        "print(confusion_matrix(y_te, yte_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2W5Vvj3MPBr",
        "outputId": "06429dd1-3bf5-4c36-c390-771b3d908995"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia treino: 1.000\n",
            "Acurácia teste : 1.000\n",
            "\n",
            "Relatório (teste):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      1.000     1.000     1.000        10\n",
            "           1      1.000     1.000     1.000        10\n",
            "\n",
            "    accuracy                          1.000        20\n",
            "   macro avg      1.000     1.000     1.000        20\n",
            "weighted avg      1.000     1.000     1.000        20\n",
            "\n",
            "Matriz de confusão (teste):\n",
            "[[10  0]\n",
            " [ 0 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Atividade 1 - Treinamento com base completa Diabetes"
      ],
      "metadata": {
        "id": "7CiPx772BwTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------ Perceptron POO ------------------\n",
        "class Perceptron:\n",
        "    def __init__(self, taxa=0.3, epocas=3000):\n",
        "        self.taxa = taxa\n",
        "        self.epocas = epocas\n",
        "        self.w = None\n",
        "        self.historico_acc = []\n",
        "\n",
        "    @staticmethod\n",
        "    def _add_bias(X):\n",
        "        return np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def _heaviside(z):\n",
        "        return (z >= 0).astype(int)\n",
        "\n",
        "    def fit(self, X, y, plot=False):\n",
        "        Xb = self._add_bias(X)\n",
        "        self.w = np.zeros(Xb.shape[1])\n",
        "        melhor_acc, melhor_w = 0.0, self.w.copy()\n",
        "\n",
        "        for _ in range(self.epocas):\n",
        "            erros = 0\n",
        "            idx = np.arange(len(Xb))\n",
        "            np.random.shuffle(idx)\n",
        "            for i in idx:\n",
        "                net = np.dot(Xb[i], self.w)\n",
        "                out = np.heaviside(net, 0)\n",
        "                e = y[i] - out\n",
        "                if e != 0:\n",
        "                    self.w += self.taxa * e * Xb[i]\n",
        "                    acc = (self.predict(X) == y).mean()\n",
        "                    self.historico_acc.append(acc)\n",
        "                    if acc > melhor_acc:\n",
        "                        melhor_acc, melhor_w = acc, self.w.copy()\n",
        "                    erros += 1\n",
        "            if erros == 0:\n",
        "                print(\"Convergiu!\")\n",
        "                break\n",
        "\n",
        "        self.w = melhor_w\n",
        "        print(f\"\\nMelhor acurácia (treino): {melhor_acc:.3f}\")\n",
        "        if plot and self.historico_acc:\n",
        "            plt.figure()\n",
        "            plt.plot(self.historico_acc)\n",
        "            plt.xlabel(\"Atualizações\")\n",
        "            plt.ylabel(\"Acurácia (treino)\")\n",
        "            plt.title(\"Evolução da Acurácia\")\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        Xb = self._add_bias(X)\n",
        "        return self._heaviside(np.dot(Xb, self.w))\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return (self.predict(X) == y).mean()\n",
        "\n",
        "\n",
        "# ------------------ Carregar base completa ------------------\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "cols = [\"preg\",\"plas\",\"pres\",\"skin\",\"insu\",\"mass\",\"pedi\",\"age\",\"class\"]\n",
        "df = pd.read_csv(url, header=None, names=cols)\n",
        "\n",
        "X_all = df.iloc[:, :-1].to_numpy(float)  # 8 features\n",
        "y_all = df.iloc[:, -1].to_numpy(int)     # rótulo 0/1\n",
        "\n",
        "# ------------------ Split 80/20 (sem sklearn) ------------------\n",
        "rng = np.random.default_rng(42)\n",
        "idx = rng.permutation(len(X_all))\n",
        "cut = int(0.8 * len(X_all))\n",
        "tr, te = idx[:cut], idx[cut:]\n",
        "\n",
        "X_tr, y_tr = X_all[tr], y_all[tr]\n",
        "X_te, y_te = X_all[te], y_all[te]\n",
        "\n",
        "# ------------------ Normalização (usa APENAS treino) ------------------\n",
        "mu = X_tr.mean(axis=0, keepdims=True)\n",
        "sd = X_tr.std(axis=0, keepdims=True) + 1e-12\n",
        "Xtr_n = (X_tr - mu) / sd\n",
        "Xte_n = (X_te - mu) / sd\n",
        "\n",
        "# ------------------ Treinar e avaliar ------------------\n",
        "modelo = Perceptron(taxa=0.1, epocas=100).fit(Xtr_n, y_tr, plot=False)\n",
        "\n",
        "acc_tr = modelo.score(Xtr_n, y_tr)\n",
        "acc_te = modelo.score(Xte_n, y_te)\n",
        "\n",
        "print(f\"\\nAcurácia treino: {acc_tr:.3f}\")\n",
        "print(f\"Acurácia teste : {acc_te:.3f}\")\n",
        "print(f\"Pesos finais (bias + 8):\\n{modelo.w}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3I6JN_uCS2-",
        "outputId": "3e80b1bb-0f81-404e-cbca-bdcac055d16d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Melhor acurácia (treino): 0.777\n",
            "\n",
            "Acurácia treino: 0.777\n",
            "Acurácia teste : 0.805\n",
            "Pesos finais (bias + 8):\n",
            "[-0.4         0.10221959  0.6029698  -0.0620309   0.06875877  0.09180629\n",
            "  0.37699755  0.23338484  0.0721811 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verificação do modelo"
      ],
      "metadata": {
        "id": "HiKR77cKL4sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Carregar base Pima Indians ---\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "cols = [\"preg\",\"plas\",\"pres\",\"skin\",\"insu\",\"mass\",\"pedi\",\"age\",\"class\"]\n",
        "df = pd.read_csv(url, header=None, names=cols)\n",
        "\n",
        "X = df.iloc[:, :-1].to_numpy(float)\n",
        "y = df.iloc[:, -1].to_numpy(int)\n",
        "\n",
        "# Separar treino/teste (80/20) ---\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Normalização (só com base no treino) ---\n",
        "scaler = StandardScaler()\n",
        "Xtr_n = scaler.fit_transform(X_tr)\n",
        "Xte_n = scaler.transform(X_te)\n",
        "\n",
        "# Treinar Perceptron (sklearn) ---\n",
        "modelo = Perceptron(\n",
        "    penalty=None,     # sem regularização (como o perceptron “clássico”)\n",
        "    alpha=0.0001,     # ignorado se penalty=None\n",
        "    max_iter=50000,\n",
        "    eta0=0.1,         # taxa de aprendizado\n",
        "    tol=True,         # desliga early stopping\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo.fit(Xtr_n, y_tr)\n",
        "\n",
        "# Avaliar ---\n",
        "ytr_pred = modelo.predict(Xtr_n)\n",
        "yte_pred = modelo.predict(Xte_n)\n",
        "\n",
        "acc_tr = accuracy_score(y_tr, ytr_pred)\n",
        "acc_te = accuracy_score(y_te, yte_pred)\n",
        "\n",
        "print(f\"Acurácia treino: {acc_tr:.3f}\")\n",
        "print(f\"Acurácia teste : {acc_te:.3f}\")\n",
        "\n",
        "print(\"\\nRelatório (teste):\")\n",
        "print(classification_report(y_te, yte_pred, digits=3))\n",
        "\n",
        "print(\"Matriz de confusão (teste):\")\n",
        "print(confusion_matrix(y_te, yte_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91Imu8RIL779",
        "outputId": "73f70c61-84d5-45c0-e433-47f00ec0d637"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia treino: 0.738\n",
            "Acurácia teste : 0.727\n",
            "\n",
            "Relatório (teste):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.784     0.800     0.792       100\n",
            "           1      0.615     0.593     0.604        54\n",
            "\n",
            "    accuracy                          0.727       154\n",
            "   macro avg      0.700     0.696     0.698       154\n",
            "weighted avg      0.725     0.727     0.726       154\n",
            "\n",
            "Matriz de confusão (teste):\n",
            "[[80 20]\n",
            " [22 32]]\n"
          ]
        }
      ]
    }
  ]
}