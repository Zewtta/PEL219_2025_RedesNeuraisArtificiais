{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkz6Otrw80S4zIk2Dzv1Ee",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zewtta/PEL219_2025_RedesNeuraisArtificiais/blob/main/PEL219_MLP_Backpropagation_Matheus_Vieira.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tarefa 2 - MLP Backpropagation"
      ],
      "metadata": {
        "id": "xFA0LPTMcZEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Aluno: Matheus Vieira"
      ],
      "metadata": {
        "id": "WP5mroQfcgrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading dos dados"
      ],
      "metadata": {
        "id": "BYiTNw5ccWJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "\n",
        "colunas = [\"sepallength\", \"sepalwidth\", \"petallength\", \"petalwidth\", \"class\"]\n",
        "df = pd.read_csv(url, names=colunas)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYszeWHtehNY",
        "outputId": "03e6a2d1-57ee-48e8-a8ec-fd23b48e54fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepallength  sepalwidth  petallength  petalwidth        class\n",
            "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
            "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
            "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
            "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
            "4          5.0         3.6          1.4         0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SksAYifcKte",
        "outputId": "b51f0689-3311-438f-998a-ec4c2458fba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n",
            "(150,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def load_iris():\n",
        "\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "    data = urlopen(url).read().decode(\"utf-8\").strip().splitlines()\n",
        "\n",
        "    X, y = [], []\n",
        "    label_map = {\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2}\n",
        "    for line in data:\n",
        "        if not line:\n",
        "            continue\n",
        "        parts = line.split(\",\")\n",
        "        if len(parts) != 5:\n",
        "            continue\n",
        "        feats = list(map(float, parts[:4]))\n",
        "        label = label_map[parts[4]]\n",
        "        X.append(feats)\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(X, dtype=np.float64), np.array(y, dtype=np.int64)\n",
        "\n",
        "\n",
        "X, y = load_iris()\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "#X são os dados de input\n",
        "#y são os resultados de classificação, onde 0 é a iris setosa, 1 é a iris versicolor e 2 a iris virgginica\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP backpropagation"
      ],
      "metadata": {
        "id": "7ZXksTw3erMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from urllib.request import urlopen\n",
        "\n",
        "\n",
        "def load_iris():\n",
        "\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "    data = urlopen(url).read().decode(\"utf-8\").strip().splitlines()\n",
        "\n",
        "    X, y = [], []\n",
        "    label_map = {\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2}\n",
        "    for line in data:\n",
        "        if not line:\n",
        "            continue\n",
        "        parts = line.split(\",\")\n",
        "        if len(parts) != 5:\n",
        "            continue\n",
        "        feats = list(map(float, parts[:4]))\n",
        "        label = label_map[parts[4]]\n",
        "        X.append(feats)\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(X, dtype=np.float64), np.array(y, dtype=np.int64)\n",
        "\n",
        "\n",
        "def train_test_split_np(X, y, test_size=0.3, seed=42):\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = np.arange(len(X))\n",
        "    rng.shuffle(idx)\n",
        "    X = X[idx]\n",
        "    y = y[idx]\n",
        "    n_test = int(round(test_size * len(X)))\n",
        "    X_test = X[:n_test]\n",
        "    y_test = y[:n_test]\n",
        "    X_train = X[n_test:]\n",
        "    y_train = y[n_test:]\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def one_hot(y, num_classes):\n",
        "\n",
        "    oh = np.zeros((y.size, num_classes))\n",
        "    oh[np.arange(y.size), y] = 1.0\n",
        "    return oh\n",
        "\n",
        "\n",
        "def confusion_matrix(y_true, y_pred, num_classes):\n",
        "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        cm[t, p] += 1\n",
        "    return cm\n",
        "\n",
        "\n",
        "# MLP (4-9-3) com Sigmoide + MSE\n",
        "class MLP:\n",
        "    \"\"\"\n",
        "    MLP 4-9-3 (regra 2n+1 -> 2*4+1=9)\n",
        "    - 1 camada escondida\n",
        "    - Sigmoide na oculta\n",
        "    - Sigmoide na saída\n",
        "    - Erro quadrático médio (MSE)\n",
        "    - Treino com gradiente descendente (batch)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_inputs=4, n_hidden=9, n_outputs=3,\n",
        "                 learning_rate=0.05, seed=0):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_outputs = n_outputs\n",
        "        self.lr = learning_rate\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self._init_params()\n",
        "\n",
        "    def _init_params(self):\n",
        "        \"\"\"\n",
        "        Inicializa pesos com valores pequenos e aleatórios |w| <= 0.1\n",
        "        \"\"\"\n",
        "        lim = 0.1\n",
        "        self.W1 = self.rng.uniform(-lim, lim, size=(self.n_inputs, self.n_hidden))\n",
        "        self.b1 = np.zeros((1, self.n_hidden))\n",
        "\n",
        "        self.W2 = self.rng.uniform(-lim, lim, size=(self.n_hidden, self.n_outputs))\n",
        "        self.b2 = np.zeros((1, self.n_outputs))\n",
        "\n",
        "    # ----------------- ativações -----------------\n",
        "    @staticmethod\n",
        "    def _sigmoid(z):\n",
        "        return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "    @staticmethod\n",
        "    def _dsigmoid(a):\n",
        "        # derivada em função da saída s = f(net): f'(net) = s * (1 - s)\n",
        "        return a * (1.0 - a)\n",
        "\n",
        "    # ----------------- forward -----------------\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Fase feed-forward:\n",
        "        X -> camada escondida -> camada de saída\n",
        "        \"\"\"\n",
        "        Z1 = X @ self.W1 + self.b1\n",
        "        A1 = self._sigmoid(Z1)\n",
        "\n",
        "        Z2 = A1 @ self.W2 + self.b2\n",
        "        A2 = self._sigmoid(Z2)  # sigmoide na saída\n",
        "\n",
        "        cache = {\"X\": X, \"Z1\": Z1, \"A1\": A1, \"Z2\": Z2, \"A2\": A2}\n",
        "        return A2, cache\n",
        "\n",
        "    # ----------------- loss -----------------\n",
        "    @staticmethod\n",
        "    def _mse(pred, y_onehot):\n",
        "        \"\"\"\n",
        "        Erro quadrático médio:\n",
        "        E = (1/2m) * sum_{p,j} (t_j^p - s_j^p)^2\n",
        "        \"\"\"\n",
        "        return 0.5 * np.mean((pred - y_onehot) ** 2)\n",
        "\n",
        "    # ----------------- backward -----------------\n",
        "    def backward(self, cache, y_onehot):\n",
        "        \"\"\"\n",
        "        Fase feed-backward (backprop):\n",
        "        calcula gradientes dW1, db1, dW2, db2.\n",
        "        \"\"\"\n",
        "        X = cache[\"X\"]\n",
        "        A1 = cache[\"A1\"]\n",
        "        A2 = cache[\"A2\"]\n",
        "        m = X.shape[0]\n",
        "\n",
        "        # Camada de saída: sigmoide + MSE\n",
        "        # erro = A2 - t\n",
        "        dA2 = (A2 - y_onehot)                   # (m, n_outputs)\n",
        "        dZ2 = dA2 * self._dsigmoid(A2)          # (m, n_outputs)\n",
        "        dW2 = (A1.T @ dZ2) / m                  # (n_hidden, n_outputs)\n",
        "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Camada escondida\n",
        "        dA1 = dZ2 @ self.W2.T                  # (m, n_hidden)\n",
        "        dZ1 = dA1 * self._dsigmoid(A1)         # (m, n_hidden)\n",
        "        dW1 = (X.T @ dZ1) / m                  # (n_inputs, n_hidden)\n",
        "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "\n",
        "        grads = {\"dW1\": dW1, \"db1\": db1,\n",
        "                 \"dW2\": dW2, \"db2\": db2}\n",
        "        return grads\n",
        "\n",
        "    # ----------------- update -----------------\n",
        "    def _update_params(self, grads):\n",
        "        \"\"\"\n",
        "        Atualiza pesos na direção oposta ao gradiente\n",
        "        \"\"\"\n",
        "        self.W1 -= self.lr * grads[\"dW1\"]\n",
        "        self.b1 -= self.lr * grads[\"db1\"]\n",
        "        self.W2 -= self.lr * grads[\"dW2\"]\n",
        "        self.b2 -= self.lr * grads[\"db2\"]\n",
        "\n",
        "    # ----------------- fit -----------------\n",
        "    def fit(self, X, y, X_val=None, y_val=None, epochs=1000, verbose=True):\n",
        "        \"\"\"\n",
        "        Treino da MLP com gradiente descendente \"batch\":\n",
        "        em cada época, usa todos os padrões de treinamento.\n",
        "        \"\"\"\n",
        "        num_classes = self.n_outputs\n",
        "        y_oh = one_hot(y, num_classes)\n",
        "\n",
        "        for ep in range(1, epochs + 1):\n",
        "            # Forward\n",
        "            y_pred, cache = self.forward(X)\n",
        "            loss = self._mse(y_pred, y_oh)\n",
        "\n",
        "            # Backward\n",
        "            grads = self.backward(cache, y_oh)\n",
        "\n",
        "            # Atualiza pesos\n",
        "            self._update_params(grads)\n",
        "\n",
        "            if verbose and (ep == 1 or ep % 100 == 0 or ep == epochs):\n",
        "                if X_val is not None and y_val is not None:\n",
        "                    y_val_pred, _ = self.forward(X_val)\n",
        "                    y_val_oh = one_hot(y_val, num_classes)\n",
        "                    val_loss = self._mse(y_val_pred, y_val_oh)\n",
        "                    y_val_pred_cls = np.argmax(y_val_pred, axis=1)\n",
        "                    val_acc = np.mean(y_val_pred_cls == y_val)\n",
        "                    print(f\"Epoch {ep:4d} | loss={loss:.4f} | val_loss={val_loss:.4f} | val_acc={val_acc:.3f}\")\n",
        "                else:\n",
        "                    print(f\"Epoch {ep:4d} | loss={loss:.4f}\")\n",
        "\n",
        "    # ----------------- predict -----------------\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Pega a classe como o neurônio de saída com maior ativação (argmax)\n",
        "        \"\"\"\n",
        "        probs, _ = self.forward(X)\n",
        "        return np.argmax(probs, axis=1)\n",
        "\n",
        "    # ----------------- evaluate -----------------\n",
        "    def evaluate(self, X, y):\n",
        "        \"\"\"\n",
        "        Calcula acurácia e matriz de confusão.\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "        acc = np.mean(y_pred == y)\n",
        "        cm = confusion_matrix(y, y_pred, self.n_outputs)\n",
        "        return acc, cm\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Carrega dados\n",
        "    X, y = load_iris()\n",
        "\n",
        "    # 2. Split 70/30 (hold-out) sem sklearn\n",
        "    X_train, X_test, y_train, y_test = train_test_split_np(X, y, test_size=0.3, seed=42)\n",
        "\n",
        "    # 3. Cria MLP 4-9-3 (regra 2n+1 -> 2*4+1=9)\n",
        "    mlp = MLP(n_inputs=4, n_hidden=9, n_outputs=3,\n",
        "              learning_rate=0.05, seed=0)\n",
        "\n",
        "    # 4. Treina\n",
        "    mlp.fit(X_train, y_train, X_val=X_test, y_val=y_test,\n",
        "            epochs=1500, verbose=True)\n",
        "\n",
        "    # 5. Avalia\n",
        "    acc, cm = mlp.evaluate(X_test, y_test)\n",
        "    print(\"\\nAcurácia de teste:\", round(acc, 4))\n",
        "    print(\"Matriz de confusão (linhas=real, cols=predito):\\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHc2HQTQeq-Y",
        "outputId": "c252c46e-1a27-4d8b-9a4c-0393b14a3ef0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    1 | loss=0.1228 | val_loss=0.1229 | val_acc=0.311\n",
            "Epoch  100 | loss=0.1116 | val_loss=0.1120 | val_acc=0.311\n",
            "Epoch  200 | loss=0.1100 | val_loss=0.1104 | val_acc=0.622\n",
            "Epoch  300 | loss=0.1091 | val_loss=0.1095 | val_acc=0.622\n",
            "Epoch  400 | loss=0.1080 | val_loss=0.1083 | val_acc=0.622\n",
            "Epoch  500 | loss=0.1063 | val_loss=0.1066 | val_acc=0.622\n",
            "Epoch  600 | loss=0.1038 | val_loss=0.1042 | val_acc=0.622\n",
            "Epoch  700 | loss=0.1005 | val_loss=0.1009 | val_acc=0.644\n",
            "Epoch  800 | loss=0.0962 | val_loss=0.0967 | val_acc=0.978\n",
            "Epoch  900 | loss=0.0911 | val_loss=0.0916 | val_acc=0.800\n",
            "Epoch 1000 | loss=0.0856 | val_loss=0.0861 | val_acc=0.733\n",
            "Epoch 1100 | loss=0.0802 | val_loss=0.0808 | val_acc=0.711\n",
            "Epoch 1200 | loss=0.0755 | val_loss=0.0761 | val_acc=0.711\n",
            "Epoch 1300 | loss=0.0715 | val_loss=0.0722 | val_acc=0.711\n",
            "Epoch 1400 | loss=0.0683 | val_loss=0.0691 | val_acc=0.711\n",
            "Epoch 1500 | loss=0.0658 | val_loss=0.0667 | val_acc=0.711\n",
            "\n",
            "Acurácia de teste: 0.7111\n",
            "Matriz de confusão (linhas=real, cols=predito):\n",
            " [[14  0  0]\n",
            " [ 0  1 13]\n",
            " [ 0  0 17]]\n"
          ]
        }
      ]
    }
  ]
}